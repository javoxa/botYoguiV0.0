# botYoguiV0.1
Bot no oficial del departamento de F√≠sica de UNSa
# Proyecto Bot IA ‚Äì Validaci√≥n de Tagging SQL con LLM

Este repositorio contiene un **prototipo funcional** de un sistema basado en **LLM (Large Language Model)** para la **clasificaci√≥n y etiquetado sem√°ntico de consultas** orientadas a bases de datos SQL, con foco en **validar la calidad de los tags generados** a partir de interacciones reales de usuarios.

Esta primera versi√≥n aun no es apta para **escalar a producci√≥n** (se actualizar√° en versiones futuras), sino realizar **pruebas controladas con un n√∫mero acotado de usuarios** para ajustar:
- prompts
- reglas de tagging
- estructura de consultas SQL generadas o asistidas por IA

---

## Objetivo del proyecto

- Evaluar la capacidad de un LLM (Qwen2) para:
  - interpretar consultas en lenguaje natural
  - asignar **tags sem√°nticos estructurados**
  - facilitar la posterior traducci√≥n a SQL
- Validar estos tags mediante **uso real** (hasta ~50 usuarios pico)
- Iterar r√°pidamente sobre prompts y reglas sin costos de infraestructura de producci√≥n

---

## Arquitectura general

El proyecto est√° dividido en tres componentes principales:

### 1. Backend ‚Äì Servidor de inferencia LLM
- Implementado con **FastAPI + vLLM**
- Soporta:
  - inferencia as√≠ncrona
  - batching continuo
  - control de concurrencia y backpressure
- Dise√±ado para correr en GPU (local o cloud)

backend/
- "inference_server.py": servidor principal de inferencia, con un setup por defecto para una A4000 (en nube recomiendo rtx 3090)
- "descargar_qwen3.py": script auxiliar para descarga del modelo qwen2.5 instruct 7b q5 awq

---

### 2. Base de datos
- Esquema SQL versionado
- Migraciones iniciales
- Scripts de generaci√≥n de SQL a partir de datasets estructurados

üìÅ database/
- schema/: definici√≥n de tablas e √≠ndices
- migrations: migraciones SQL de los prototipos iniciales y que se usaron para los .csv
- scripts de inicializaci√≥n y generaci√≥n de datos

‚ö†Ô∏è **Se incluyen datos reales de informaci√≥n p√∫blica, pero no dumps de producci√≥n**

---

### 3. Frontend / Bot
- Bot conversacional (Telegram)
- Conexi√≥n a PostgreSQL
- Uso del backend LLM para:
  - interpretaci√≥n sem√°ntica
  - recuperaci√≥n de informaci√≥n
  - asistencia en consultas

frontend/bot/
- l√≥gica del bot
- retriever
- utilidades
- integraci√≥n con base de datos

---

## Alcance del testing

Este repositorio est√° preparado para:

- Tests cortos
- Uso concurrente moderado (‚â§ 50 usuarios pico)
- Validaci√≥n cualitativa y cuantitativa de:
  - tags SQL
  - consistencia sem√°ntica
  - errores frecuentes del modelo

**No est√° escalado para alta disponibilidad ni escalado horizontal**
Futuras versiones, traeran una estructura que permita el escalado a otras facultades. Esta primera instancia esta pensada en solo la Facultad de Ciencias Exactas

---

## Requisitos

- Python 3.10+
- GPU NVIDIA con soporte CUDA 12.x, este proyecto se desarrollo en una RTX A4000, se recomienda hardare igual o superior. Aunque con ajustes minimos (ver inference_server.py se puede utilizar hardware de arquitectura Ampere+ con menos VRAM (ej. RTX 3060).
- Docker (recomendado)
- PostgreSQL (local o contenedor)
- Drivers NVIDIA (560+) + CUDA (12.x) compatibles con vLLM

---

## Ejecuci√≥n local (resumen)

1. Clonar el repositorio:

   git clone <repo_url>
   cd proyecto-bot-ia
   -ajustar parametros en .env (keys y dem√°s)
   -levantar servicios
   docker-compose up --build
   -√≥ ejecutar manualmente
   python backend/inference_server.py
   √≥
   python run_bot.py

